version: '3'
services:
  ai:
    image: "formartha/ai1899:latest"
    ports:
      - "5555:5555"
    networks:
      - int_network
    depends_on:
      - qdrant-container
      - redis
    volumes:
      - model-volume:/lm-model-home
    environment:
      - SENTENCE_TRANSFORMERS_HOME=/lm-model-home
      - LM_MODEL=${LM_MODEL}
      - QDRANT=qdrant-container
      - QDRANTPORT=6333
      - REDDIS_CELERY=redis://redis:6379/0
    deploy:
      resources:
        limits:
          cpus: "1" # recommended 4
          memory: 1G # recommended 4
    command: python3 server.py

  qdrant-container:
    image: "ghcr.io/qdrant/qdrant/qdrant:v1.7.3-unprivileged"
    networks:
      - int_network
    ports:
      - "6333:6333"
    deploy:
      resources:
        limits:
          cpus: "1" # recommended 2
          memory: 1G # recommended 2

  redis:
    hostname: "redis"
    image: "redis:latest"
    ports:
      - "6379:6379"
    networks:
      - int_network

  redis-commander:
    image: "rediscommander/redis-commander:latest"
    environment:
      - REDIS_HOSTS=local:redis:6379
    ports:
      - "8081:8081"
    networks:
      - int_network

  celery-worker:
    image: "formartha/ai1899:latest"  # Use the same image as ai service, assuming it has Celery installed
    networks:
      - int_network
    depends_on:
      - ai
    volumes:
      - model-volume:/lm-model-home
    environment:
      - SENTENCE_TRANSFORMERS_HOME=/lm-model-home
      - LM_MODEL=${LM_MODEL}
      - QDRANT=qdrant-container
      - QDRANTPORT=6333
      - REDDIS_CELERY=redis://redis:6379/0
    command: celery --app=tasks worker --loglevel=INFO --pool=solo

networks:
  int_network:
    driver: bridge

volumes:
  model-volume:
    driver: local
    driver_opts:
      type: none
      device: ${DEVICE} # /path/to/your/model
      o: bind